## 二分类
 准确率 precision 、召回率 recall、F值
首先定义混淆矩阵：

1) 二分类情况：
|预测标签|真实标签|
|||正例|反例|
||正例|真正（TP）|假反（FN）|
||反例|假正（FP）|真反（TN）|


对于计算机程序而言，如果按照类别作为索引，一般是从小到大排序的。即
表mat
010真反FN假正（FP）1假负（FN）真正（FP）
备注：行索引表示真实标签（与sklearn 混淆矩阵一致），列索引表示预测标签
![混淆矩阵与pr]()

由于precision和 recall 是负相关的两个量，因此，为寻求一个precision和 recall的平衡点：precision高、 recall也不要太低；recall高、 precision也不要太低；定义了F1值为P和R的调和均值。

但有时候实际上对模型precision的要求更高些，例如对疾病的诊断；或者有时候更偏向recall，如网页推荐。因此更一般的平衡precision和 recall，定义了一般的 

 值





二分类任务precision与recall不一样（不区分宏平均与微平均）
对于二分类来说，precision的分母TP+FP其实就是预测结果中，正确预测出为正类的个数加上本来不是正类，却预测成正类的个数，这其实就是precsion中为1的个数之和。
对于二分类来说，recall的分母TP+FN，其实就是预测结果中，正确预测为正类的个数，加上本来是正类，却没有预测出来的个数，这其实就是truu_label中，为1的个数之和。
对于二分类来说，在预测和真实标签中，1的个数并不一定相等，所以precision于recall并不一定相等。比如pred=[0,1,1,0],ture=[1,1,1,0]
对于多分类来说，在计算每一类的分数时，为正的个数并不一定是相等的。因此，对于每一类来说，precision于recall并不一定相等。
对于多分类来说，一般预测和真实标签中，不包含0，多以，预测和真实标签中，其包含的正值是相同的，所以对于micro来说，precision于recall是相等的。
在多标签基于样本的任务中，预测和真实的正类个数目很难一致，因此，precision于recall也不一定是相等的。
在多标签j基于标签的任务中，在预测和真实标签中，每一个类别为正的数目并不一定一致，因此，precision于recall也不一定相等。

多分类
对于多分类来说，是对每个类求分别求precision和recall，最后要处以类的个数，所以在labels很大，而样本个数少时候，不合适，值会变得很小。
对于多分类：
回顾二分类中的P、R、F指标，它们都是针对正例这一类别上计算的，因此，对于多分类问题，可以对每一个类别下都进行P和R的计算，计算时将当前类当做正例，其他所有类一起当做反例，相当于多次的二分类问题。
例：150个样本，真实情况是A、B、C三类各50个，预测结果的混淆矩阵如下：

如果行索引代表真实值，列索引代表预测值，则每一行中错误的预测（不包含斜对角的元素）表示本来应该是正类的，却预测成了负类，即FN。代表召回指标。召回指标更看重真实指标的覆盖率，实际上预测出来了多少，因此，真实值的行的错误可以认为是代表召回，即FN
每一列错误的预测表示：1 错误的预测，2预测出来为正。即FP，代表精确指标。由于精确（precision）更看重模型的预测正确性，因此，预测的每一列（错误预测）相当于是对模型预测正确能力的一个评估，代表了FP。
上表中，行代表真实，列代表预测。
对于每一类的准确率、召回率、F1值性能度量：

但是为了评估模型的全局性能，就需要对所有类别下的性能进行度量，有两种方式：

或：


## 多标签分类
https://www.cnblogs.com/liaohuiqiang/p/9339996.html
1） Hamming Loss

P：样本数 、Q：标签数 、 | ……|：错误样本的个数
例：

2）one-error

P：样本数
排序后的前k个标签，不在Yi中的个数


